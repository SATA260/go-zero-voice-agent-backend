// Code generated by protoc-gen-go. DO NOT EDIT.
// versions:
// 	protoc-gen-go v1.36.10
// 	protoc        v6.32.0
// source: llmservice.proto

package pb

import (
	protoreflect "google.golang.org/protobuf/reflect/protoreflect"
	protoimpl "google.golang.org/protobuf/runtime/protoimpl"
	structpb "google.golang.org/protobuf/types/known/structpb"
	reflect "reflect"
	sync "sync"
	unsafe "unsafe"
)

const (
	// Verify that this generated code is sufficiently up-to-date.
	_ = protoimpl.EnforceVersion(20 - protoimpl.MinVersion)
	// Verify that runtime/protoimpl is sufficiently up-to-date.
	_ = protoimpl.EnforceVersion(protoimpl.MaxVersion - 20)
)

// 流式输出选项
type StreamOptions struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// 是否在输出的最后一行显示所使用的Token数 (可选)
	IncludeUsage  bool `protobuf:"varint,1,opt,name=include_usage,json=includeUsage,proto3" json:"include_usage,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *StreamOptions) Reset() {
	*x = StreamOptions{}
	mi := &file_llmservice_proto_msgTypes[0]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *StreamOptions) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*StreamOptions) ProtoMessage() {}

func (x *StreamOptions) ProtoReflect() protoreflect.Message {
	mi := &file_llmservice_proto_msgTypes[0]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use StreamOptions.ProtoReflect.Descriptor instead.
func (*StreamOptions) Descriptor() ([]byte, []int) {
	return file_llmservice_proto_rawDescGZIP(), []int{0}
}

func (x *StreamOptions) GetIncludeUsage() bool {
	if x != nil {
		return x.IncludeUsage
	}
	return false
}

// 音频输出选项
type AudioOptions struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// 音色 (可选)
	Voice string `protobuf:"bytes,1,opt,name=voice,proto3" json:"voice,omitempty"`
	// 格式, e.g., "wav", "mp3" (可选)
	Format        string `protobuf:"bytes,2,opt,name=format,proto3" json:"format,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *AudioOptions) Reset() {
	*x = AudioOptions{}
	mi := &file_llmservice_proto_msgTypes[1]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *AudioOptions) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*AudioOptions) ProtoMessage() {}

func (x *AudioOptions) ProtoReflect() protoreflect.Message {
	mi := &file_llmservice_proto_msgTypes[1]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use AudioOptions.ProtoReflect.Descriptor instead.
func (*AudioOptions) Descriptor() ([]byte, []int) {
	return file_llmservice_proto_rawDescGZIP(), []int{1}
}

func (x *AudioOptions) GetVoice() string {
	if x != nil {
		return x.Voice
	}
	return ""
}

func (x *AudioOptions) GetFormat() string {
	if x != nil {
		return x.Format
	}
	return ""
}

// 大语言模型配置
type LlmConfig struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// API基础URL (必选)
	BaseUrl string `protobuf:"bytes,1,opt,name=baseUrl,proto3" json:"baseUrl,omitempty"`
	// API密钥 (必选)
	ApiKey string `protobuf:"bytes,2,opt,name=apiKey,proto3" json:"apiKey,omitempty"`
	// 模型名称 (必选)
	Model string `protobuf:"bytes,3,opt,name=model,proto3" json:"model,omitempty"`
	// 是否流式输出 (可选)
	Stream bool `protobuf:"varint,4,opt,name=stream,proto3" json:"stream,omitempty"`
	// 采样温度，控制模型生成文本的多样性 (可选)
	Temperature float64 `protobuf:"fixed64,5,opt,name=temperature,proto3" json:"temperature,omitempty"`
	// 核采样的概率阈值 (可选)
	TopP float64 `protobuf:"fixed64,6,opt,name=top_p,json=topP,proto3" json:"top_p,omitempty"`
	// 生成过程中采样候选集的大小 (可选)
	TopK int64 `protobuf:"varint,7,opt,name=top_k,json=topK,proto3" json:"top_k,omitempty"`
	// 是否开启思考模式 (可选)
	EnableThinking bool `protobuf:"varint,8,opt,name=enable_thinking,json=enableThinking,proto3" json:"enable_thinking,omitempty"`
	// 控制模型生成文本时的内容重复度（已弃用，请使用presence_penalty）(可选)
	RepetitionPenalty float64 `protobuf:"fixed64,9,opt,name=repetition_penalty,json=repetitionPenalty,proto3" json:"repetition_penalty,omitempty"`
	// 控制模型生成文本时的内容重复度 (可选)
	PresencePenalty float64 `protobuf:"fixed64,10,opt,name=presence_penalty,json=presencePenalty,proto3" json:"presence_penalty,omitempty"`
	// 返回内容的格式, e.g., "text", "json_object" (可选)
	ResponseFormat string `protobuf:"bytes,11,opt,name=response_format,json=responseFormat,proto3" json:"response_format,omitempty"`
	// 流式输出特定选项 (可选)
	StreamOptions *StreamOptions `protobuf:"bytes,12,opt,name=stream_options,json=streamOptions,proto3" json:"stream_options,omitempty"`
	// 输出数据的模态, e.g., "text", "audio" (可选)
	Modalities []string `protobuf:"bytes,13,rep,name=modalities,proto3" json:"modalities,omitempty"`
	// 输出音频的音色与格式 (可选)
	Audio *AudioOptions `protobuf:"bytes,14,opt,name=audio,proto3" json:"audio,omitempty"`
	// 本次请求返回的最大 Token 数 (可选)
	MaxTokens int64 `protobuf:"varint,15,opt,name=max_tokens,json=maxTokens,proto3" json:"max_tokens,omitempty"`
	// 随机种子，用于结果可复现 (可选)
	Seed int64 `protobuf:"varint,16,opt,name=seed,proto3" json:"seed,omitempty"`
	// 是否启用互联网搜索 (可选)
	EnableSearch  bool `protobuf:"varint,17,opt,name=enable_search,json=enableSearch,proto3" json:"enable_search,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *LlmConfig) Reset() {
	*x = LlmConfig{}
	mi := &file_llmservice_proto_msgTypes[2]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *LlmConfig) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*LlmConfig) ProtoMessage() {}

func (x *LlmConfig) ProtoReflect() protoreflect.Message {
	mi := &file_llmservice_proto_msgTypes[2]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use LlmConfig.ProtoReflect.Descriptor instead.
func (*LlmConfig) Descriptor() ([]byte, []int) {
	return file_llmservice_proto_rawDescGZIP(), []int{2}
}

func (x *LlmConfig) GetBaseUrl() string {
	if x != nil {
		return x.BaseUrl
	}
	return ""
}

func (x *LlmConfig) GetApiKey() string {
	if x != nil {
		return x.ApiKey
	}
	return ""
}

func (x *LlmConfig) GetModel() string {
	if x != nil {
		return x.Model
	}
	return ""
}

func (x *LlmConfig) GetStream() bool {
	if x != nil {
		return x.Stream
	}
	return false
}

func (x *LlmConfig) GetTemperature() float64 {
	if x != nil {
		return x.Temperature
	}
	return 0
}

func (x *LlmConfig) GetTopP() float64 {
	if x != nil {
		return x.TopP
	}
	return 0
}

func (x *LlmConfig) GetTopK() int64 {
	if x != nil {
		return x.TopK
	}
	return 0
}

func (x *LlmConfig) GetEnableThinking() bool {
	if x != nil {
		return x.EnableThinking
	}
	return false
}

func (x *LlmConfig) GetRepetitionPenalty() float64 {
	if x != nil {
		return x.RepetitionPenalty
	}
	return 0
}

func (x *LlmConfig) GetPresencePenalty() float64 {
	if x != nil {
		return x.PresencePenalty
	}
	return 0
}

func (x *LlmConfig) GetResponseFormat() string {
	if x != nil {
		return x.ResponseFormat
	}
	return ""
}

func (x *LlmConfig) GetStreamOptions() *StreamOptions {
	if x != nil {
		return x.StreamOptions
	}
	return nil
}

func (x *LlmConfig) GetModalities() []string {
	if x != nil {
		return x.Modalities
	}
	return nil
}

func (x *LlmConfig) GetAudio() *AudioOptions {
	if x != nil {
		return x.Audio
	}
	return nil
}

func (x *LlmConfig) GetMaxTokens() int64 {
	if x != nil {
		return x.MaxTokens
	}
	return 0
}

func (x *LlmConfig) GetSeed() int64 {
	if x != nil {
		return x.Seed
	}
	return 0
}

func (x *LlmConfig) GetEnableSearch() bool {
	if x != nil {
		return x.EnableSearch
	}
	return false
}

// 可供模型调用的工具
type Tool struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// 工具类型，目前仅支持 "function"
	Type string `protobuf:"bytes,1,opt,name=type,proto3" json:"type,omitempty"`
	// 函数定义
	Function      *Function `protobuf:"bytes,2,opt,name=function,proto3" json:"function,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *Tool) Reset() {
	*x = Tool{}
	mi := &file_llmservice_proto_msgTypes[3]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *Tool) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*Tool) ProtoMessage() {}

func (x *Tool) ProtoReflect() protoreflect.Message {
	mi := &file_llmservice_proto_msgTypes[3]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use Tool.ProtoReflect.Descriptor instead.
func (*Tool) Descriptor() ([]byte, []int) {
	return file_llmservice_proto_rawDescGZIP(), []int{3}
}

func (x *Tool) GetType() string {
	if x != nil {
		return x.Type
	}
	return ""
}

func (x *Tool) GetFunction() *Function {
	if x != nil {
		return x.Function
	}
	return nil
}

// 函数定义
type Function struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// 函数名称
	Name string `protobuf:"bytes,1,opt,name=name,proto3" json:"name,omitempty"`
	// 函数功能的描述，模型将根据此描述决定何时以及如何调用该函数
	Description string `protobuf:"bytes,2,opt,name=description,proto3" json:"description,omitempty"`
	// 函数接受的参数，以 JSON Schema 格式描述。
	// 使用 google.protobuf.Struct 可以灵活地表示任意JSON对象结构。
	Parameters    *structpb.Struct `protobuf:"bytes,3,opt,name=parameters,proto3" json:"parameters,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *Function) Reset() {
	*x = Function{}
	mi := &file_llmservice_proto_msgTypes[4]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *Function) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*Function) ProtoMessage() {}

func (x *Function) ProtoReflect() protoreflect.Message {
	mi := &file_llmservice_proto_msgTypes[4]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use Function.ProtoReflect.Descriptor instead.
func (*Function) Descriptor() ([]byte, []int) {
	return file_llmservice_proto_rawDescGZIP(), []int{4}
}

func (x *Function) GetName() string {
	if x != nil {
		return x.Name
	}
	return ""
}

func (x *Function) GetDescription() string {
	if x != nil {
		return x.Description
	}
	return ""
}

func (x *Function) GetParameters() *structpb.Struct {
	if x != nil {
		return x.Parameters
	}
	return nil
}

type ChatMsg struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Role          string                 `protobuf:"bytes,1,opt,name=role,proto3" json:"role,omitempty"` //System,User,Assistant,tool
	Content       string                 `protobuf:"bytes,2,opt,name=content,proto3" json:"content,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *ChatMsg) Reset() {
	*x = ChatMsg{}
	mi := &file_llmservice_proto_msgTypes[5]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *ChatMsg) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*ChatMsg) ProtoMessage() {}

func (x *ChatMsg) ProtoReflect() protoreflect.Message {
	mi := &file_llmservice_proto_msgTypes[5]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use ChatMsg.ProtoReflect.Descriptor instead.
func (*ChatMsg) Descriptor() ([]byte, []int) {
	return file_llmservice_proto_rawDescGZIP(), []int{5}
}

func (x *ChatMsg) GetRole() string {
	if x != nil {
		return x.Role
	}
	return ""
}

func (x *ChatMsg) GetContent() string {
	if x != nil {
		return x.Content
	}
	return ""
}

// 创建聊天请求
type CreateChatReq struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// 大语言模型配置 (必选)
	LlmConfig *LlmConfig `protobuf:"bytes,1,opt,name=llmConfig,proto3" json:"llmConfig,omitempty"`
	// 可供模型调用的工具列表 (可选)
	Tools []*Tool `protobuf:"bytes,2,rep,name=tools,proto3" json:"tools,omitempty"`
	// 消息
	Messages      []*ChatMsg `protobuf:"bytes,3,rep,name=messages,proto3" json:"messages,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *CreateChatReq) Reset() {
	*x = CreateChatReq{}
	mi := &file_llmservice_proto_msgTypes[6]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *CreateChatReq) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*CreateChatReq) ProtoMessage() {}

func (x *CreateChatReq) ProtoReflect() protoreflect.Message {
	mi := &file_llmservice_proto_msgTypes[6]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use CreateChatReq.ProtoReflect.Descriptor instead.
func (*CreateChatReq) Descriptor() ([]byte, []int) {
	return file_llmservice_proto_rawDescGZIP(), []int{6}
}

func (x *CreateChatReq) GetLlmConfig() *LlmConfig {
	if x != nil {
		return x.LlmConfig
	}
	return nil
}

func (x *CreateChatReq) GetTools() []*Tool {
	if x != nil {
		return x.Tools
	}
	return nil
}

func (x *CreateChatReq) GetMessages() []*ChatMsg {
	if x != nil {
		return x.Messages
	}
	return nil
}

type CreateChatResp struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Id            string                 `protobuf:"bytes,1,opt,name=id,proto3" json:"id,omitempty"`
	RespMsg       *ChatMsg               `protobuf:"bytes,2,opt,name=respMsg,proto3" json:"respMsg,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *CreateChatResp) Reset() {
	*x = CreateChatResp{}
	mi := &file_llmservice_proto_msgTypes[7]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *CreateChatResp) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*CreateChatResp) ProtoMessage() {}

func (x *CreateChatResp) ProtoReflect() protoreflect.Message {
	mi := &file_llmservice_proto_msgTypes[7]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use CreateChatResp.ProtoReflect.Descriptor instead.
func (*CreateChatResp) Descriptor() ([]byte, []int) {
	return file_llmservice_proto_rawDescGZIP(), []int{7}
}

func (x *CreateChatResp) GetId() string {
	if x != nil {
		return x.Id
	}
	return ""
}

func (x *CreateChatResp) GetRespMsg() *ChatMsg {
	if x != nil {
		return x.RespMsg
	}
	return nil
}

var File_llmservice_proto protoreflect.FileDescriptor

const file_llmservice_proto_rawDesc = "" +
	"\n" +
	"\x10llmservice.proto\x12\x02pb\x1a\x1cgoogle/protobuf/struct.proto\"4\n" +
	"\rStreamOptions\x12#\n" +
	"\rinclude_usage\x18\x01 \x01(\bR\fincludeUsage\"<\n" +
	"\fAudioOptions\x12\x14\n" +
	"\x05voice\x18\x01 \x01(\tR\x05voice\x12\x16\n" +
	"\x06format\x18\x02 \x01(\tR\x06format\"\xbd\x04\n" +
	"\tLlmConfig\x12\x18\n" +
	"\abaseUrl\x18\x01 \x01(\tR\abaseUrl\x12\x16\n" +
	"\x06apiKey\x18\x02 \x01(\tR\x06apiKey\x12\x14\n" +
	"\x05model\x18\x03 \x01(\tR\x05model\x12\x16\n" +
	"\x06stream\x18\x04 \x01(\bR\x06stream\x12 \n" +
	"\vtemperature\x18\x05 \x01(\x01R\vtemperature\x12\x13\n" +
	"\x05top_p\x18\x06 \x01(\x01R\x04topP\x12\x13\n" +
	"\x05top_k\x18\a \x01(\x03R\x04topK\x12'\n" +
	"\x0fenable_thinking\x18\b \x01(\bR\x0eenableThinking\x12-\n" +
	"\x12repetition_penalty\x18\t \x01(\x01R\x11repetitionPenalty\x12)\n" +
	"\x10presence_penalty\x18\n" +
	" \x01(\x01R\x0fpresencePenalty\x12'\n" +
	"\x0fresponse_format\x18\v \x01(\tR\x0eresponseFormat\x128\n" +
	"\x0estream_options\x18\f \x01(\v2\x11.pb.StreamOptionsR\rstreamOptions\x12\x1e\n" +
	"\n" +
	"modalities\x18\r \x03(\tR\n" +
	"modalities\x12&\n" +
	"\x05audio\x18\x0e \x01(\v2\x10.pb.AudioOptionsR\x05audio\x12\x1d\n" +
	"\n" +
	"max_tokens\x18\x0f \x01(\x03R\tmaxTokens\x12\x12\n" +
	"\x04seed\x18\x10 \x01(\x03R\x04seed\x12#\n" +
	"\renable_search\x18\x11 \x01(\bR\fenableSearch\"D\n" +
	"\x04Tool\x12\x12\n" +
	"\x04type\x18\x01 \x01(\tR\x04type\x12(\n" +
	"\bfunction\x18\x02 \x01(\v2\f.pb.FunctionR\bfunction\"y\n" +
	"\bFunction\x12\x12\n" +
	"\x04name\x18\x01 \x01(\tR\x04name\x12 \n" +
	"\vdescription\x18\x02 \x01(\tR\vdescription\x127\n" +
	"\n" +
	"parameters\x18\x03 \x01(\v2\x17.google.protobuf.StructR\n" +
	"parameters\"7\n" +
	"\aChatMsg\x12\x12\n" +
	"\x04role\x18\x01 \x01(\tR\x04role\x12\x18\n" +
	"\acontent\x18\x02 \x01(\tR\acontent\"\x85\x01\n" +
	"\rCreateChatReq\x12+\n" +
	"\tllmConfig\x18\x01 \x01(\v2\r.pb.LlmConfigR\tllmConfig\x12\x1e\n" +
	"\x05tools\x18\x02 \x03(\v2\b.pb.ToolR\x05tools\x12'\n" +
	"\bmessages\x18\x03 \x03(\v2\v.pb.ChatMsgR\bmessages\"G\n" +
	"\x0eCreateChatResp\x12\x0e\n" +
	"\x02id\x18\x01 \x01(\tR\x02id\x12%\n" +
	"\arespMsg\x18\x02 \x01(\v2\v.pb.ChatMsgR\arespMsg2A\n" +
	"\n" +
	"Llmservice\x123\n" +
	"\n" +
	"CreateChat\x12\x11.pb.CreateChatReq\x1a\x12.pb.CreateChatRespB\x06Z\x04./pbb\x06proto3"

var (
	file_llmservice_proto_rawDescOnce sync.Once
	file_llmservice_proto_rawDescData []byte
)

func file_llmservice_proto_rawDescGZIP() []byte {
	file_llmservice_proto_rawDescOnce.Do(func() {
		file_llmservice_proto_rawDescData = protoimpl.X.CompressGZIP(unsafe.Slice(unsafe.StringData(file_llmservice_proto_rawDesc), len(file_llmservice_proto_rawDesc)))
	})
	return file_llmservice_proto_rawDescData
}

var file_llmservice_proto_msgTypes = make([]protoimpl.MessageInfo, 8)
var file_llmservice_proto_goTypes = []any{
	(*StreamOptions)(nil),   // 0: pb.StreamOptions
	(*AudioOptions)(nil),    // 1: pb.AudioOptions
	(*LlmConfig)(nil),       // 2: pb.LlmConfig
	(*Tool)(nil),            // 3: pb.Tool
	(*Function)(nil),        // 4: pb.Function
	(*ChatMsg)(nil),         // 5: pb.ChatMsg
	(*CreateChatReq)(nil),   // 6: pb.CreateChatReq
	(*CreateChatResp)(nil),  // 7: pb.CreateChatResp
	(*structpb.Struct)(nil), // 8: google.protobuf.Struct
}
var file_llmservice_proto_depIdxs = []int32{
	0, // 0: pb.LlmConfig.stream_options:type_name -> pb.StreamOptions
	1, // 1: pb.LlmConfig.audio:type_name -> pb.AudioOptions
	4, // 2: pb.Tool.function:type_name -> pb.Function
	8, // 3: pb.Function.parameters:type_name -> google.protobuf.Struct
	2, // 4: pb.CreateChatReq.llmConfig:type_name -> pb.LlmConfig
	3, // 5: pb.CreateChatReq.tools:type_name -> pb.Tool
	5, // 6: pb.CreateChatReq.messages:type_name -> pb.ChatMsg
	5, // 7: pb.CreateChatResp.respMsg:type_name -> pb.ChatMsg
	6, // 8: pb.Llmservice.CreateChat:input_type -> pb.CreateChatReq
	7, // 9: pb.Llmservice.CreateChat:output_type -> pb.CreateChatResp
	9, // [9:10] is the sub-list for method output_type
	8, // [8:9] is the sub-list for method input_type
	8, // [8:8] is the sub-list for extension type_name
	8, // [8:8] is the sub-list for extension extendee
	0, // [0:8] is the sub-list for field type_name
}

func init() { file_llmservice_proto_init() }
func file_llmservice_proto_init() {
	if File_llmservice_proto != nil {
		return
	}
	type x struct{}
	out := protoimpl.TypeBuilder{
		File: protoimpl.DescBuilder{
			GoPackagePath: reflect.TypeOf(x{}).PkgPath(),
			RawDescriptor: unsafe.Slice(unsafe.StringData(file_llmservice_proto_rawDesc), len(file_llmservice_proto_rawDesc)),
			NumEnums:      0,
			NumMessages:   8,
			NumExtensions: 0,
			NumServices:   1,
		},
		GoTypes:           file_llmservice_proto_goTypes,
		DependencyIndexes: file_llmservice_proto_depIdxs,
		MessageInfos:      file_llmservice_proto_msgTypes,
	}.Build()
	File_llmservice_proto = out.File
	file_llmservice_proto_goTypes = nil
	file_llmservice_proto_depIdxs = nil
}
